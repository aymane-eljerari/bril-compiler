---
execute:
  echo: true
format:
  html: default
  revealjs:
    chalkboard: true
    code-fold: true
    code-line-numbers: true
    echo: true
    output-file: revealjs_diverg.qmd
    output-location: slide
    scrollable: true
    slideNumber: c/t
sidebar: false
title: 'divergent flow '

---

## What is the cost of divergence 

```{cuda}
__global__ void dec2zero(int* v, int N) { 
    int xIndex = blockIdx.x*blockDim.x+threadIdx.x;   
    if (xIndex < N) {
             while (v[xIndex] > 0) { v[xIndex]--;     
             }     
        } 
} 
```

Depending on how we initialize the vector, we get different times and different subtracts

1. Size of array 1048576
1. Threads Per Block = 256
1. Blocks In Grid    = 4096

## some initializers 

```{C}
  // all 1
  for (int i = 0; i < n; i++) {
    A[i] = 1; 
  }
  // subtracts 1048576
  // time      0.1 ms
```

```{c}
// decreasing values from n-1 to 0
  for (int i = 0; i < n; i++) {
    A[i] = n - i - 1;  // count should be N*(n+1)/2 = 54975572...
  }
  // subtracts 549755289600
  // time  45.7 ms
```

```{c}
// Fill function to set all elements of the array to the middle value of n
  for (int i = 0; i < n; i++) {
    A[i] = n / 2;  // count should be N*N/2 54975572...
    // subtracts 549755813888
    // time  45.6 ms
```


```{c}
// Fill function to set alternate elements to 0 or n
  for (int i = 0; i < n; i++) {
    A[i] = 0;
    if (i%2){ A[i] = n;} 
    // subtacts 549755813888
    // time 83.9 ms
  }
```

## divergence example 

```__global__ void example(float* v){
    if (v[tid]) < 2.0){
        v[tid] = /=2;
    } else {
        v[tid] = 0;
    }
}

and in ptx

```
1. b0: r1 = addr v[tid]
2. f1 = load r1
3. p1 = set.lt f0, 0.0

5. @p1? Bzr: f2 = div f1, 2
6. @p1? jmp Bst

7. !@p1? b1: f2 = 0.0

8. Bst: store r1, f2
```


```{mermaid}
%%{init: {"flowchart": {"htmlLabels": false}} }%%

Graph TB
B0--> Bzr
B0--> B1
Bzr--> Bst
b1 --> Bst
```

## what happens to implement this?

## harware version 1 (pre volta nvidia chips)

There is a hardware stack called the simt-stack, each entry is a pc and a 32 bit active mask.
When hardware reachs an if- push 3 entries 
pc then, mask for then
pc else,  mask for else
pc reconvergence pt, mask for recovergence 

```

                          t0 t1 t2 t3    stack
a:                        r  r  r  r      a: 1111
--------------------------------------------------------
  if (tid% 4 < 2) {       r  r  r  r      b  1100
                                          c  0011
                                          f  1111
----------------------------------------------------------
    b:                    r r   -  -      c 0011
    c:                    r r   -  -      f  1111
-------------------------------------------------
  } else {                
    d:                    - -   r r 
    e:                    - -   r r
  }
  f:                                    stack is empty    
```

at else pc matches tos
at f pc matches tos  

rules:
1. divergent paths execute serially 
1. threads execute in lock step
1. recoverge at immed post dominator 

easy to find post dominator for reducible control flow 

some code deadlocks:

1: *mutex = 0; 
2: 3 while(!atomicCAS(mutex,0,1)); 
3:    // Critical Section 
4: atomicExch(mutex,0);


## volta and newer 

[possible structure](https://arxiv.org/pdf/2407.02944)

Handles unstructured code nicely 
always makes forward progress 

adds a new set of registers called barrier registers 






## code for an if statement reconverga nbce 

in AMD terms 

save the exec mask
set exect mask to running threads
do the then 
invert the exec mask if there is an else 
do the else 
restore the exec mask 

where in the cfg do we restore the exec mask 


